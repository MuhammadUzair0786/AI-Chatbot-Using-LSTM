
# ğŸ¤– AI Chatbot Using LSTM

This project is a simple AI-powered chatbot built using an LSTM-based deep learning model. It uses natural language processing (NLP) techniques to classify user input into predefined intents and generate appropriate responses.

---

## ğŸ“Œ Features

- Built using **TensorFlow** and **Keras**
- Uses **LSTM** for understanding text patterns
- Trained on a custom `intents.json` file
- Saves trained model and tokenizer for future inference
- Can be extended or integrated into a web/chat interface

---

## ğŸ“ Dataset (`intents.json`)

The dataset includes multiple user intents like:

```json
{
  "intents": [
    {
      "tag": "greeting",
      "patterns": ["Hi", "Hey", "Hello", "Is anyone there?"],
      "responses": ["Hello!", "Hi there!", "Greetings!"]
    },
    {
      "tag": "goodbye",
      "patterns": ["Bye", "See you later", "Goodbye"],
      "responses": ["See you!", "Have a nice day!", "Bye! Come back again soon."]
    },
    {
      "tag": "thanks",
      "patterns": ["Thanks", "Thank you", "That's helpful"],
      "responses": ["You're welcome!", "No problem!", "Happy to help!"]
    }
  ]
}
```

Each intent includes:
- `tag`: Category of the intent
- `patterns`: Possible user inputs
- `responses`: Bot replies (randomly selected)

---

## ğŸ§  Model Architecture

- **Embedding Layer** â€“ Converts words into vectors
- **LSTM Layer** â€“ Captures temporal patterns in sequences
- **Dense Layers** â€“ Fully connected layers for classification
- **Output Layer** â€“ Uses `softmax` activation for multi-class output

---

## ğŸ› ï¸ Training Pipeline

1. Load and parse `intents.json`
2. Tokenize and pad the sequences
3. Label encode the intent tags
4. Build the model:
   - `Embedding` â†’ `LSTM` â†’ `Dense`
5. Train the model on the prepared data
6. Save:
   - Trained model: `chat_model.h5`
   - Tokenizer: `tokenizer.pickle`
   - Label encoder: `label_encoder.pickle`

---

## ğŸš€ How to Run

### 1. Clone the Repository

```bash
git clone https://github.com/MuhammadUzair0786/AI-Chatbot-Using-LSTM.git
cd AI-Chatbot-Using-LSTM
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run Training

Use the Jupyter Notebook `Chatbot_Using_LSTM.ipynb` to train the model  
or use the saved model to directly test it.

### 4. Load Model for Inference

```python
from tensorflow.keras.models import load_model
import pickle

model = load_model('chat_model.h5')

with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

with open('label_encoder.pickle', 'rb') as enc:
    lbl_encoder = pickle.load(enc)
```

---

## ğŸ§ª Sample Output

```
You: Hi
Bot: Hello there!

You: Thanks
Bot: You're welcome!

You: Bye
Bot: Goodbye! Take care.
```

---

## ğŸ§° Tech Stack

- Python
- TensorFlow / Keras
- Scikit-learn
- NumPy
- Pickle
- Jupyter Notebook

---

## ğŸ“š Learning Outcome

âœ… Learned how to:
- Structure chatbot intent data
- Preprocess text for NLP
- Apply LSTM for sequence modeling
- Save and reuse trained models

---

## ğŸ”— Project Link

ğŸ‘‰ [GitHub Repository](https://github.com/MuhammadUzair0786/AI-Chatbot-Using-LSTM)

---

## ğŸ™Œ Letâ€™s Connect

If you're working on a similar project or have suggestions, feel free to connect with me!
